# Research-paper
paper or articles that I've read
+ Neural Network
http://neuralnetworksanddeeplearning.com/chap4.html
https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c


+ NLP
Entity embedding paper https://arxiv.org/pdf/1604.06737.pdf
Drop connect LSTM [1708.02182 Regularizing and Optimizing LSTM Language Models]( [https://arxiv.org/abs/1708.02182](https://arxiv.org/abs/1708.02182) )
ULMFit https://zhuanlan.zhihu.com/p/42618178
Attention https://zhuanlan.zhihu.com/p/43493999
Transformer https://zhuanlan.zhihu.com/p/44121378 
Transformer https://zhuanlan.zhihu.com/p/48508221
Google BERT https://zhuanlan.zhihu.com/p/46652512
XLNet https://zhuanlan.zhihu.com/p/70257427

+CNN
CNN https://medium.com/雞雞與兔兔的工程世界/機器學習-ml-note-cnn演化史-alexnet-vgg-inception-resnet-keras-coding-668f74879306
Image Kernels explained visually http://setosa.io/ev/image-kernels/
CNNs from different viewpoints – ImpactAI – Medium https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c
Calculator https://fomoro.com/project/receptive-field-calculator
EfficientNet Depth Width(Channel) Resolution https://blog.csdn.net/u014380165/article/details/90812249
ResNet https://ithelp.ithome.com.tw/articles/10204727

